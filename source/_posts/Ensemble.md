---
title: Ensemble Model
date: 2022-09-15
categories:
  - Data Analysis
  - Model 
tags: 
  - Ensemble Model
  - ML Analysis
  - Python
---

### 1. Ensemble Model

`ì–´ë– í•œ í•œ í˜„ìƒì— ëŒ€í•œ ë‹µì„ ì–»ëŠ”ë‹¤ê³  ê°€ì •í•´ë³´ì, ë§ì€ ê²½ìš°ì— í•œ ëª…ì˜ ì „ë¬¸ê°€ë³´ë‹¤ ì—¬ë ¤ ëª…ì˜ ì¼ë°˜ì¸ë“¤ì˜ ì˜ê²¬ì´ ë” ë‚˜ì€ ê²½ìš°ê°€ ìˆë‹¤.`

- ìœ„ ì˜ˆì œì™€ ë¹„ìŠ·í•˜ê²Œ, í•˜ë‚˜ì˜ ì¢‹ì€ ëª¨í˜•(íšŒê·€,ë¶„ë¥˜)ìœ¼ë¡œë¶€í„° ì˜ˆì¸¡ì„ í•˜ëŠ” ê²ƒë³´ë‹¤ ì—¬ëŸ¬ ê°œì˜ ëª¨í˜•ìœ¼ë¡œë¶€í„° ì˜ˆì¸¡ì„ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì€ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆë‹¤.
- ì´ëŸ¬í•œ ì—¬ëŸ¬ ê°œì˜ ëª¨í˜•ì„Â **ì•™ìƒë¸”**ì´ë¼ê³  ë¶€ë¥´ê³ , ì—¬ëŸ¬ ê°œì˜ ëª¨í˜•ì„ ì¡°í™”ë¡­ê²Œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì„Â **ì•™ìƒë¸” í•™ìŠµ**ì´ë¼ê³  í•œë‹¤.
- ê·¸ë¦¬ê³  6ì£¼ì°¨ì—ì„œ ë°°ìš´ ê²°ì • íŠ¸ë¦¬ ëª¨í˜•ì´ í•˜ë‚˜ê°€ ì•„ë‹ˆë¼, í›ˆë ¨ ì„¸íŠ¸ë¥¼ ë¬´ì‘ìœ„ë¡œ ë‹¤ë¥¸ ì„œë¸Œì…‹ìœ¼ë¡œ ë§Œë“¤ì–´ì„œ ê²°ì • íŠ¸ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“¤ê³ , ë§ì€ ëª¨í˜•ë“¤ ì¤‘ì—ì„œ ê°€ì¥ ë§ì€ ì„ íƒì„ ë°›ì€ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì•™ìƒë¸” ëª¨í˜•ì„Â **ëœë¤í¬ë ˆìŠ¤íŠ¸**ë¼ê³  í•œë‹¤.
- ì˜¤ëŠ˜ë‚ ì˜ ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ ê°€ì¥ ê°•ë ¥í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ í•˜ë‚˜ì´ë‹¤.
- ê·¸ë¦¬ê³  ë¨¸ì‹ ëŸ¬ë‹ ëŒ€íšŒì—ì„œ ìš°ìŠ¹í•˜ëŠ” ì†”ë£¨ì…˜ë“¤ì€ ëŒ€ë¶€ë¶„ ì•™ìƒë¸” ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ì„œ ìµœê³  ì„±ëŠ¥ì„ ë‚¸ë‹¤.
- ë’¤ì—ì„œ ì•™ìƒë¸” ë°©ë²•ë“¤ ì¤‘Â **ë°°ê¹…**ì„ ì„¤ëª…í•  ê²ƒì´ë‹¤.
- íˆ¬í‘œ ê¸°ë°˜ ë¶„ë¥˜ê¸°
    
    ![](images/Ensemble/image.png)
    
    - í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ì¢…ë¥˜ì˜ ë¶„ë¥˜ê¸°ë“¤ë¡œ í›ˆë ¨ì‹œì¼°ë‹¤ê³  ê°€ì •í•´ë³´ì.
    - ìœ„ì—ì„œ ì–¸ê¸‰í•œëŒ€ë¡œ í•˜ë‚˜ì˜ ì¢‹ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤, ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë¶„ë¥˜ê¸°ë“¤ì´ ê°€ì¥ ë§ì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì€ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“œëŠ” ë§¤ìš° ê°„ë‹¨í•œ ë°©ë²•ì´ë‹¤.
    - ì´ë ‡ê²Œ ë‹¤ìˆ˜ê²°ì˜ íˆ¬í‘œë¡œ ì •í•´ì§€ëŠ” ë¶„ë¥˜ê¸°ë¥¼Â **hard voting(ì§‘ì ‘ íˆ¬í‘œ)**Â ë¶„ë¥˜ê¸°ë¼ê³  í•œë‹¤.
    - ë†€ëê²Œë„ ìœ„ ëª¨ë¸ ì¤‘ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ì˜ ì •í™•ë„ë³´ë‹¤ ë‹¤ìˆ˜ê²°ì„ í†µí•´ ì˜ˆì¸¡í•œ ì•™ìƒë¸” ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë†’ì€ ê²½ìš°ê°€ ë§ë‹¤.
    - ì´ë ‡ê²Œ ëœë¤ ì¶”ì¸¡ë³´ë‹¤ ì¡°ê¸ˆ ë” ë†’ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”Â **weak learner(ì•½í•œ í•™ìŠµê¸°)**Â ê°€ ì¶©ë¶„íˆ ë§ê³  ë‹¤ì–‘í•˜ë‹¤ë©´ strong learner(ê°•í•œ í•™ìŠµê¸°)ê°€ ë  ìˆ˜ ìˆë‹¤.
    
    ![](images/Ensemble/image2.png)
    
    
    `ì–´ë–»ê²Œ ì•½í•œ í•™ìŠµê¸°ê°€ ê°•í•œ í•™ìŠµê¸°ê°€ ë˜ì–´ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆì„ê¹Œ?, ì´ ì§ˆë¬¸ì€ "í° ìˆ˜ì˜ ë²•ì¹™"ìœ¼ë¡œ ì„¤ëª…ë  ìˆ˜ ìˆë‹¤.`
    
    
    - ë¨¼ì €, 50:50ì˜ ë™ì „ì´ ì•„ë‹ˆë¼, 51:49ì˜ ë¶ˆê· í˜•í•˜ê²Œ ì•ë©´ê³¼ ë’·ë©´ì´ ë‚˜ì˜¤ëŠ” ë™ì „ì´ ìˆë‹¤ê³  ê°€ì •ì„ í•´ë³´ì.
    - ì´ ë™ì „ì„ 1,000ë²ˆì„ ë˜ì§„ë‹¤ë©´ ê±°ì˜ ì•ë©´ 510ë²ˆê³¼ ë’·ë©´ 490ë²ˆì´ ë‚˜ì˜¬ ê²ƒì´ë‹¤.
    - ìˆ˜í•™ì ìœ¼ë¡œ 1,000ë²ˆì„ ë˜ì¡Œì„ ë•Œ ì•ë©´ì´ ë” ë§ê²Œ ë‚˜ì˜¤ëŠ” í™•ë¥ ì€ ê±°ì˜ 75% ì •ë„ ëœë‹¤.
    - ìˆ˜í•™ì ìœ¼ë¡œ 10,000ë²ˆì„ ë˜ì¡Œì„ ë•Œ ì•ë©´ì´ ë” ë§ê²Œ ë‚˜ì˜¤ëŠ” í™•ë¥ ì€ ê±°ì˜ 97% ì •ë„ ëœë‹¤.
    - ìœ„ ìˆ˜í•™ì  ê³„ì‚°ì€ ì´í•­ë¶„í¬ì˜ í™•ë¥  ì§ˆëŸ‰ í•¨ìˆ˜ë¡œ ê³„ì‚° ê°€ëŠ¥í•˜ë‹¤. ex) 1-scipy.stats.binom.cdf(499,1000,0.51) = 0.747
    - ìœ„ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìš°ë¦¬ì˜ ì•½í•œ ë¶„ë¥˜ê¸°(51%) 1,000ê°œë¡œ ì•™ìƒë¸” ëª¨í˜•ì„ êµ¬ì¶•í•˜ê³ , ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡ìœ¼ë¡œ ì‚¼ëŠ”ë‹¤ë©´ 75%, 10,000ê°œë¡œ ëª¨í˜•ì„ ë§Œë“¤ë©´ 97% ì •ë„ì˜ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.
    - í•˜ì§€ë§Œ..! ìœ„ì˜ ê³¼ì •ì€ ëª¨ë“  ë¶„ë¥˜ê¸°ê°€ ì™„ë²½í•˜ê²Œ ë…ë¦½ì´ê³ , ëª¨ë¸ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ì— ëŒ€í•´ì„œ ìƒê´€ê´€ê³„ê°€ ì—†ì„ë•Œë§Œ ê°€ëŠ¥í•˜ë‹¤.
    - ğŸŒ TIP : ì•™ìƒë¸”ì—ì„œ ì˜ˆì¸¡ê¸°ê°€ ê°€ëŠ¥í•œ ì„œë¡œ ë…ë¦½ì¼ ë•Œ ìµœê³  ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤. ê·¸ë˜ì„œ ê°€ëŠ¥í•œ ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì„œ í•™ìŠµì„ í•˜ë©´ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì˜¤ì°¨ë¥¼ ë§Œë“¤ê¸° ë•Œë¬¸ì— ì•™ìƒë¸” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.
    - ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì„œÂ **íˆ¬í‘œê¸°ë°˜ ë¶„ë¥˜ê¸°**ë¥¼ ë§Œë“œëŠ” ì˜ˆì œë¥¼ í•´ë³´ì.
    
    ```python
    from sklearn.datasets import load_iris
    from sklearn.ensemble import RandomForestClassifier,VotingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.metrics import accuracy_score
    from sklearn.model_selection import train_test_split
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    iris = load_iris()
    X = iris.data[:,2:] # ê½ƒìì˜ ê¸¸ì´, ë„ˆë¹„
    Y = iris.target
    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=2021,shuffle=True)
    
    # ì•½í•œ í•™ìŠµê¸° êµ¬ì¶•
    log_model = LogisticRegression()
    rnd_model = RandomForestClassifier()
    svm_model = SVC()
    
    # ì•™ìƒë¸” ëª¨ë¸ êµ¬ì¶•
    # ë§Œì•½ì— ëª¨ë“  ëª¨ë¸ì´ predict_proba() ë©”ì„œë“œê°€ ìˆìœ¼ë©´, ì˜ˆì¸¡ì˜ í‰ê· ì„ ë‚´ì–´ soft voting(ê°„ì ‘ íˆ¬í‘œ)ë„ í• ìˆ˜ ìˆë‹¤.
    # ê°„ì ‘ íˆ¬í‘œ ë°©ì‹ì€ í™•ë¥ ì´ ë†’ì€ íˆ¬í‘œì— ë¹„ì¤‘ì„ ë‘ê¸° ë•Œë¬¸ì— ì„±ëŠ¥ì´ ë” ë†’ë‹¤. (voting='soft' ì‚¬ìš©)
    # svcëŠ” ê¸°ë³¸ì ìœ¼ë¡œ predict_probaë¥¼ ì œê³µí•˜ì§€ ì•Šì•„, probability = True ì§€ì • í•´ì•¼ ì‚¬ìš© ê°€ëŠ¥
    # ëŒ€ì‹  svcì—ì„œ probability = Trueë¥¼ ì§€ì •í•˜ë©´ êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•´ì„œ í™•ë¥ ì„ ì¶”ì •í•˜ê¸° ë•Œë¬¸ì— í›ˆë ¨ ì†ë„ ëŠë ¤ì§
    # ëŒ€ì‹  ì„±ëŠ¥ì„ ì˜¬ë¼ê°
    voting_model = VotingClassifier(
        estimators=[('lr',log_model),('rf',rnd_model),('svc',svm_model)], # 3ê°œì˜ ì•½í•œ í•™ìŠµê¸°
        voting='hard' # ì§ì ‘ íˆ¬í‘œ(hard voting)
    )
    
    # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
    voting_model.fit(x_train,y_train)
    
    # ëª¨ë¸ ë¹„êµ
    for model in (log_model,rnd_model,svm_model,voting_model):
      model.fit(x_train,y_train)
      y_pred = model.predict(x_test)
      print(model.__class__.__name__," : ",accuracy_score(y_test,y_pred))
    
    > LogisticRegression  :  1.0
      RandomForestClassifier  :  0.9555555555555556
      SVC  :  1.0
      VotingClassifier  :  1.0
    ```
    
### 2.ë°°ê¹…ê³¼ í˜ì´ìŠ¤íŒ…
  - ì•™ìƒë¸” ëª¨í˜•ì˜ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê¸° ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ì˜¤ì°¨ë¥¼ ë§Œë“¤ì–´ì•¼ í•˜ê³ , ê·¸ëŸ¬ê¸° ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤ê³  ë°°ì› ë‹¤.
  - ë‹¤ì–‘í•œ ì˜¤ì°¨ë¥¼ ë§Œë“¤ê¸°ìœ„í•œ ë‹¤ë¥¸ í•˜ë‚˜ì˜ ë°©ë²•ìœ¼ë¡œëŠ” í›ˆë ¨ ì„¸íŠ¸ì˜ ì„œë¸Œì…‹ì„ ë¬´ì‘ìœ„ë¡œ êµ¬ì„±í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ìˆë‹¤. ì´ë¥¼Â **ë°°ê¹…**ê³¼Â **í˜ì´ìŠ¤íŒ…**ì´ë¼ê³  ë¶€ë¥¸ë‹¤.
  - **ë°°ê¹…**Â : í›ˆë ¨ ì„¸íŠ¸ì˜ ì¤‘ë³µì„ í—ˆìš©í•˜ì—¬ ìƒ˜í”Œë§ì„ í•˜ëŠ” ë°©ì‹ (í†µê³„í•™ì—ì„œëŠ” "ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘"ì´ë¼ê³ ë„ ë¶€ë¦„)
  - **í˜ì´ìŠ¤íŒ…**Â : í›ˆë ¨ ì„¸íŠ¸ì˜ ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•Šê³  ìƒ˜í”Œë§ í•˜ëŠ” ë°©ì‹
  - ë°°ê¹…ì€ ê° ì˜ˆì¸¡ê¸°ê°€ í•™ìŠµí•˜ëŠ” ì„œë¸Œì…‹ì— ë‹¤ì–‘ì„±ì„ ì¦ê°€ì‹œí‚¤ë¯€ë¡œ í˜ì´ìŠ¤íŒ…ë³´ë‹¤ í¸í–¥ì´ ì¡°ê¸ˆ ë” ë†’ë‹¤.
  - í•˜ì§€ë§Œ ë°°ê¹…ì€ ì˜ˆì¸¡ê¸°ë“¤ì˜ ìƒê´€ê´€ê³„ë¥¼ ì¤„ì´ë¯€ë¡œ ì•™ìƒë¸”ì˜ ë¶„ì‚°ì„ ê°ì†Œ ì‹œí‚¨ë‹¤.
  - ì „ë°˜ì ìœ¼ë¡œ ë°°ê¹…ì´ ë” ë‚˜ì€ ëª¨ë¸ì„ ë§Œë“¤ì§€ë§Œ, ì‹œê°„ê³¼ ì¥ë¹„ê°€ ì¢‹ë‹¤ë©´ êµì°¨ê²€ì¦ìœ¼ë¡œ ë°°ê¹…ê³¼ í˜ì´ìŠ¤íŒ…ì„ ë‘˜ë‹¤ í•´ë³´ë©´ ì¢‹ë‹¤.
  
    **1. ì‚¬ì´í‚·ëŸ°ì˜ ë°°ê¹…ê³¼ í˜ì´ìŠ¤íŒ…**
    
    ```python
    from sklearn.ensemble import BaggingClassifier
    from sklearn.tree import DecisionTreeClassifier
    
    # ëª¨ë¸ êµ¬ì¶•
    # BaggingClassifierì—ì„œ ì‚¬ìš©í•œ ë¶„ë¥˜ê¸°ê°€ í´ë˜ìŠ¤ í™•ë¥ ì¶”ì •(predict_proba)ì´ ê°€ëŠ¥í•˜ë©´ ìë™ìœ¼ë¡œ ê°„ì ‘ íˆ¬í‘œ ì‚¬ìš© 
    bag_model = BaggingClassifier(
        DecisionTreeClassifier(), # ì•½í•œ í•™ìŠµê¸°(ê²°ì • íŠ¸ë¦¬)
        n_estimators=500, # ì•½í•œ í•™ìŠµê¸°(ê²°ì • íŠ¸ë¦¬) 500ê°œ ìƒì„±
        max_samples=0.05, # 0.0~1.0 ì‚¬ì´ ì‹¤ìˆ˜ ì„ íƒ(ì‹¤ìˆ˜ x ìƒ˜í”Œ ìˆ˜) í˜¹ì€ ìƒ˜í”Œìˆ˜ ì§€ì •
        bootstrap=True, # True : ë°°ê¹…, False : í˜ì´ìŠ¤íŒ…
        n_jobs=-1 # í›ˆë ¨ê³¼ ì˜ˆì¸¡ì— ì‚¬ìš©í•  CPU ì½”ì–´ ìˆ˜ (-1 : ê°€ìš©í•œ ëª¨ë“  ì½”ì–´ ì‚¬ìš©)
    )
    
    # ëª¨ë¸ í•™ìŠµ
    bag_model.fit(x_train,y_train)
    
    # ëª¨ë¸ ì˜ˆì¸¡
    y_pred = bag_model.predict(x_test)
    
    # ëª¨ë¸ í‰ê°€
    print(bag_model.__class__.__name__," : ",accuracy_score(y_test,y_pred))
    > BaggingClassifier  :  0.9777777777777777
    ```
    
    ![](images/Ensemble/image3.png)
    
    - ë‹¨ì¼ ê²°ì • íŠ¸ë¦¬ì™€ ë°°ê¹…ì„ ì‚¬ìš©í•œ ê²°ì •íŠ¸ë¦¬ ì•™ìƒë¸”ì˜ ê²°ì •ê²½ê³„ë¥¼ ë¹„êµí•´ë³´ë©´ íŠ¸ë¦¬ ì•™ìƒë¸”ì´ ë”ìš± ì¼ë°˜í™”ê°€ ì˜ ëœê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
    
    **2. oob í‰ê°€**
    
    - ë°°ê¹…(ì¤‘ë³µ í—ˆìš© ìƒ˜í”Œë§)ì„ í•˜ë‹¤ë³´ë©´ í‰ê· ì ìœ¼ë¡œ í›ˆë ¨ ìƒ˜í”Œì˜ ì•½ 63%ì •ë„ë§Œ ì¶”ì¶œë˜ê³  ë‚˜ë¨¸ì§€ ì•½ 37%ëŠ” ì¶”ì¶œë˜ì§€ ì•Šê³ , ì´ë ‡ê²Œ ì¶”ì¶œë˜ì§€ ì•Šì€ ìƒ˜í”Œë“¤ì„ oob(out-of-bag)ìƒ˜í”Œì´ë¼ê³  ë¶€ë¥¸ë‹¤.
    - ì˜ˆì¸¡ê¸°ê°€ í›ˆë ¨ë˜ëŠ” ë™ì•ˆì—ëŠ” oobìƒ˜í”Œì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ê²€ì¦ ì„¸íŠ¸ë‚˜ êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  oobìƒ˜í”Œë§Œì„ ê°€ì§€ê³  ëª¨ë¸ ìµœì í™”ë¥¼ ìœ„í•œ í‰ê°€ë¥¼ í•  ìˆ˜ ìˆë‹¤.
    - ì•™ìƒë¸”ì˜ í‰ê°€ëŠ” ê° ì˜ˆì¸¡ê¸°ì˜ oobí‰ê°€ì˜ í‰ê· ìœ¼ë¡œ í™•ì¸í•œë‹¤.
    
    ```python
    # ëª¨ë¸ êµ¬ì¶•
    bag_model = BaggingClassifier(
        base_estimator = DecisionTreeClassifier(),
        n_estimators = 500,
        bootstrap = True,
        n_jobs = -1,
        oob_score = True # oobí‰ê°€ë¥¼ ìœ„í•´ Trueë¥¼ ì§€ì •í•œë‹¤.
    )
    
    # ëª¨ë¸ í•™ìŠµ
    bag_model.fit(x_train,y_train)
    
    # ëª¨ë¸ í‰ê°€(oob_score_)
    print('oob_score : ',bag_model.oob_score_)
    
    # ëª¨ë¸ í‰ê°€
    y_pred = bag_model.predict(x_test)
    print('test_score : ',accuracy_score(y_test,y_pred))
    >oob_score  :  0.9523809523809523
     test_score :  0.9333333333333333
    ```
    
### 3. ëœë¤ í¬ë ˆìŠ¤íŠ¸
  - ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë°°ê¹…ë°©ë²•ì„ ì‚¬ìš©í•œ ê²°ì •íŠ¸ë¦¬ ì•™ìƒë¸” ëª¨ë¸ì´ë‹¤.
  - ê·¸ë˜ì„œ BaggingClassifierì— DecisionTreeClassifierë¥¼ ë„£ëŠ” ëŒ€ì‹ , RandomForestClassifierë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
  - ê·¸ë˜ì„œ RandomForestClassifierëŠ” DecisionTreeClassifierì™€ BaggingClassifier ë§¤ê°œë³€ìˆ˜ ëª¨ë‘ ê°€ì§€ê³  ìˆë‹¤.
  - ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ íŠ¸ë¦¬ì˜ ë…¸ë“œë¥¼ ë¶„í• í•  ë•Œ ì „ì²´ íŠ¹ì„± ì¤‘ì—ì„œ ìµœì„ ì˜ íŠ¹ì„±ì„ ì°¾ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë¬´ì‘ìœ„ë¡œ ì„ íƒí•œ íŠ¹ì„±ë“¤ ì¤‘ì—ì„œ ìµœì„ ì˜ íŠ¹ì„±ì„ ì°¾ëŠ” ë°©ì‹ì„ ì±„íƒí•˜ì—¬ ë¬´ì‘ìœ„ì„±ì„ ë” ê°€ì§€ê²Œ ëœë‹¤.
  - ì´ë¥¼ í†µí•´ ì•½ê°„ì˜ í¸í–¥ì€ ì†í•´ë³´ì§€ë§Œ, ë”ìš± ë‹¤ì–‘í•œ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ë¯€ë¡œ ë¶„ì‚°ì„ ì „ì²´ì ìœ¼ë¡œ ë‚®ì¶”ì–´ì„œ ë” í›Œë¥­í•œ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.
    
    ```python
    from sklearn.ensemble import RandomForestClassifier
    
    # ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ êµ¬ì¶•
    rnd_model = RandomForestClassifier(
        n_estimators = 500, # ì˜ˆì¸¡ê¸° 500ê°œ
        max_leaf_nodes = 16, # ìì‹ë…¸ë“œì˜ ìµœëŒ€ ê°œìˆ˜ 
        n_jobs = -1 # CPU ì½”ì–´ êµ¬ë™ ê°œìˆ˜
    )
    
    # ëª¨ë¸ í•™ìŠµ
    rnd_model.fit(x_train,y_train)
    
    # ëª¨ë¸ ì˜ˆì¸¡
    y_pred_rf = rnd_model.predict(x_test)
    
    # ëª¨ë¸ í‰ê°€
    print("rnd_model : ",accuracy_score(y_pred_rf,y_test))
    > rnd_model :  0.9333333333333333
    ```
    
---
- Reference
    - [https://velog.io/@changhtun1/ensemble#-ëœë¤-í¬ë ˆìŠ¤íŠ¸](https://velog.io/@changhtun1/ensemble#-%EB%9E%9C%EB%8D%A4-%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8)